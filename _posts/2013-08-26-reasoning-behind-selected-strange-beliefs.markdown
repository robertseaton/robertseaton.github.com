---
title: Reasoning Behind (Selected) Strange Beliefs
layout: post
---
People believe a lot of weird things, but these weird things seem a whole lot
less weird once you understand the reasoning behind them. In this post,
I'm going to sketch out the gist of a couple "weird" beliefs.

The hope is that once you understand why people believe weird things, you'll
stop thinking of them as crazy and realize that they, too, are human beings just
like you and me. I don't necessarily endorse the beliefs here, but they are
things that used to baffle me, but I now feel like, "I get where you're coming
from."

# Veganism

Vegans consume only non-animal products. Some
vegans will still eat *some* products, such as honey, while others might
abstain from animal products entirely, going so far as boycotting leather and even leather lookalikes.


People go vegan for different reasons. These are not
mutually exclusive.

## An argument from animal suffering

Factory farming is institutionalized cruelty on a scale that is hard to
comprehend. <a href="#citation-1"><sup>1</sup></a> Vegans who go vegan for reasons of animal suffering usually do so
based on the belief that buying factory farmed meat is wrong. Specifically, they
value not participating in animal torture more than the inconvenience of not
eating animal products.

A lot of people will retort with, "Who cares? They're animals," which strikes me
as a rationalization. If I came to your house and starting kicking your dog, you
would not like that, even though your dog is "just" an animal.

So, then, one might say: yes, but I love my dog, and I don't love the cow I'm
eating, which is fair enough. If I invited you to my house and said, "Give me a
nickel or I'm going to torture this cow", you would probably give me the nickel
(or call the police), which suggests that you, yes, *you* value animal
suffering.

At this point, you might argue, well, yes, I'll pay not to see an animal
tortured, but as long as I'm not aware of it, who cares? You could reason this
way, but it strikes me as not all that plausible. Why should torturing a cow
only be wrong when you witness it? 

## An argument from human suffering

Let us say that you do not value animal suffering, or that you do not value it
enough such that you're willing to change your eating habits. There are other
reasons why one might choose to be vegan.

Veganism is more sustainable than factory farming.<a href="#citation-2"><sup>2</sup></a>  Meat is not an efficient source of energy. Only about a fourth of the energy from the grain that we feed
cows makes it into the meat itself.<a href="#citation-3"><sup>3</sup></a> We could maintain a higher population of
happy, non-starving humans if the world was populated by vegans. That is: you
might go vegan because you value other human beings not suffering, not because
you care about animal welfare.

Further, livestock have a huge impact on the environment. Cattle farming is
responsible for dumping more carbon dioxide into the environment than transportation.<a href="#citation-4"><sup>4</sup></a> Given that we
value all the global warming doomsday scenarios not occurring, veganism
should be appealing.

## An argument from personal health

Finally, one might become a vegan because they value their own personal health
more than they value eating animal products.

Some people argue that veganism is not that healthy for you, that vegans are
missing some of the vitamins that are mostly obtained through animal products. This is
missing the point. The question should be: is the average vegan diet healthier
than the average non-vegan diet? The answer to which is almost certainly
yes.<a href="#citation-5"><sup>5,</sup></a><a href="#citation-6"><sup>6</sup></a> Comparing the ideal non-vegan diet to the average vegan diet is not a
relevant or fair comparison.

The best individual comparison might be: will a vegan diet be healthier
for me than my current diet? If so, given that you value your own health, you
should be willing to consider veganism. It is, of course, possible
that the costs of switching to a vegan diet outweigh how much you value the
health benefits, which would imply that you should not switch.

## The status quo

Another interesting question that can be posed regarding veganism is, "If you
were born into a vegan society and grew up eating a vegan diet, do you really
think your would choose to eat animal products?" Or even, "How much would you have to pay vegans to convince them to go back to eating meat?"

# Cryonics

People who sign up for cryonics do not believe in an afterlife. If you are going
to live eternally in heaven, there is no reason to freeze yourself in the
hope of being resurrected in the future. (Although, if you suspect you are going to suffer eternal damnation hell, resurrection starts to look mighty appealing.)

Those who sign up for cryonics don't necessarily believe that cryonics works or
will work, but they do believe that there is a higher probability that they will
be brought back to life by signing up for cryonics than if they don't sign up
for cryonics.

Essentially, the choice boils down to a decision between:
* The probability of resurrection given that you sign up for cryonics.
* The probability of resurrection given that you do not sign up for cryonics.

Thus, signing up for cryonics seems reasonable given that:
* You value living.
* There is no afterlife.
* It is more likely that you will be resurrected if you sign up for cryonics than if you don't.
* The expected value of signing up for cryonics outweighs the hassle of going
through the process.


# Existential risk
> People who would never dream of hurting a child hear of an existential risk, and say, "Well, maybe the human species doesn't really deserve to survive."
  <span id="quote-attribute">Eliezer Yudkowsky</span>
  
With the rise of nuclear warfare, the human race now has the ability to cause
destruction on a scale that was not possible in the past, including self-destruction. Unchecked global warming could destroy our biosphere or an especially
virulent bioweapon could kill everyone.

If we extrapolate from the past trend of technology toward more and more
control over the environment, the future seems to hold even more dangerous
technological advances (e.g. nanotechnology and [grey goo](http://en.wikipedia.org/wiki/Grey_goo)). Nick Bostrom offers the analogy of the scientific process as pulling
random technologies from an urn of possible technologies.<a href="#citation-7"><sup>7</sup></a> You never know when
you will stumble on something terrible.

The study of existential risks is the study of events that could cause human
extinction. Those in the field estimate that there is a significant chance that
humanity will not survive this century. One survey of experts placed the
probability at 19%.<a href="#citation-8"><sup>8</sup></a> 

So, given that you value your own life and those that you love, you should value
reducing the threat of human extinction.

## Future generations

Wiping out the human race not only kills all of those who are living now, but it
would also mean that future humans will never be born. In essence, human
extinction means that they never get the chance to live.

Most of the people interested in existential risk believe that future humans have
some moral significance. Even if we assume that only one billion humans can live
on the earth sustainably, and that the earth will remain habitable another
billion years, then \\( 10^{16} \\) future lives
would be lost if the human race destroys itself.<a href="#citation-7"><sup>7</sup></a> 

If you multiply a small reduction in existential risk by the number of future
human lives (an expected value calculation), you get staggering numbers. Reducing the risk of extinction by a tenth of a percent is worth as much as \\( \frac{1}{1000} * 10^{16} \\), or ten trillion future lives.

Work on existential risk seems reasonable, then, given that:
* There is a significant risk of human extinction.
* Whatever action does the most good is best (e.g. saving the most lives). 
* Future human lives have some worth.

# We're living in a computer simulation

The simulation argument argues that at least one of the following is true:

* We will go extinct before uncovering the necessary technological capability necessary to run simulations of entire worlds.
* Humans will choose not to run simulations of worlds once we have the technology necessary to do so.
* We are living in a computer simulation.

There are also a few assumptions:

* Human-level intelligence is substrate independent, meaning that it could be
  implemented via other things than brains, such as on computer hardware.
* Intelligence does not consist of some supernatural life force, like a soul.

If civilizations similar to ours inevitably go extinct, then there is no reason to
believe that we are being computer simulated. After all, who would be simulating
us?

If civilizations similar to our own don't go extinct and do invariably reach
greater levels of technological attainment, such that they can simulate worlds
like this one, they either choose not to simulate people (perhaps believing it
immoral) or we are living in a simulation.

Why is this so? An advanced civilization would be able to simulate many possible
worlds given the amount of computational power that they would control. The
number of simulated worlds, then, is some large number \\( N \\) and then number of
real, non-simulated realities is one. The probability that we just happen to be
the non-simulated civilization is \\( \frac{1}{N + 1} \\). The more simulations a civilization
would choose to run, the more likely it is that we are, right now, in a
simulation.

If advanced civilizations do not run such simulations or do not have the
capability to run the simulations, then the probability that we are currently
being simulated is near zero.

So, the reasoning for people who believe that we are currently living in a
computer simulation is something like this:

* Human-like civilizations tend to attain a level of technological advancement such that simulating entire worlds is possible.
* These civilizations choose to run many simulations.
* We are almost certainly living in a simulation.

# Singularitarianism

Singularitarianism is the idea that the future is going to look drastically
different than the present, and that it's going to happen very quickly. At the
core of singularitarianism is the idea that change, technological progress, is
accelerating. Things are improving more and more rapidly.

One common example is strong artificial
intelligence. That is: machines that are smarter than humans. If a human can
build a machine that is smarter than a human, then this machine should be able
to build a machine even smarter than itself, and so on, culminating in something different than whatever we can imagine.

Most of singularity type ideas revolve around the idea of smarter than human
intelligence, but this isn't essential. You might believe that more
technological progress enables even more progress and that this keeps
compounding on itself, such that technology improves at faster and
faster rates.

So, for example, a singularitarian might think of all the
progress that has been made in the past 100 years, and posit that a similar
amount of progress will be made in the next ten years. This would become more
and more compressed, such that the next ten years after that might encompass
something like a thousand years of progress or more. Envisioning such changes becomes impossible. What does another thousand years of progress look
like?

The reasoning, then, is something like:
* The rate of technological advancement is accelerating.
* This trend will continue into the foreseeable future, compounding on itself,
  leading to rapid, unimaginable change.

# Polyamory

Most educated people are, these days, pro gay marriage, but if you suggest that
people ought to be allowed to marry more than one person, this is crossing a
line. Most of the reasoning for allowing gay couples to marry, however, also
applies to marrying multiple partners.

Of course, you can be polyamorous without marrying multiple people, e.g. an "open relationship."

Most of the arguments against open dating (ignoring religious concerns) center
around the issue of jealousy. According to at least some people in open
relationships, jealousy is less of an issue then you might at first think, with
a couple people reporting [here](http://slatestarcodex.com/2013/04/06/polyamory-is-boring/) that it is a non-issue.

Or, if jealousy is an issue, those in polyamory communities or who engage in
open relationships figure that it is something that can be overcome. I suspect
that there is a significant selection effect going on here, though, such that
people who experience strong feelings of jealousy tend to never become
polyamorous or, once they try it, decide that it is not for them. 

All of this avoids the question, though, why be in an open relationship? Even if
jealousy is a non-issue, it must have significant benefits over traditional
relationships for it to be worthwhile.

Some reasons are:

* Humans have not evolved for monogamy. There is an innate tendency to sleep
around and fighting nature makes everyone miserable.
* Having multiple partners provides many sources of social support.
* Multiple partners have a diverse range of skills, strengths, and perspectives
  that can be drawn upon.
* Polyamory is a relationship style in the same sense that being gay is a
  relationship style. It is a stable individual trait with a sizable genetic
  component, not a choice.

# Further Reading
* For more on the environmental impact of meat production, check out [this Wikipedia page](http://en.wikipedia.org/wiki/Environmental_impact_of_meat_production). For information about sustainability arguments for veganism, there's [this page](http://en.wikipedia.org/wiki/Environmental_vegetarianism).
* According to [this informal survey](http://leiterreports.typepad.com/blog/2012/10/philosophers-eating-ethics-a-discussion-of-the-poll-results.html) of philosophers' eating habits, philosophers are ten to twenty times more likely to be vegan than the general population.
* For a critique of moral vegetarianism, there is [this paper](http://www.reasonpapers.com/pdf/03/rp_3_2.pdf).
* The (debunked) doctrine that living organism are fundamentally different from non-living things (due to a soul or life force) is called [vitalism](http://en.wikipedia.org/wiki/Vitalism).
* The importance of existential risk from an ethical standpoint is laid out in Derek Parfit's *Reasons and Persons*. Nick Bostrom describes the reasoning in [this TedX talk](http://www.youtube.com/watch?v=P0Nf3TcMiHo).
* The book *Global Catastrophic Risks* covers the threats facing humanity's continued existence.
* The original and more thorough treatment of the simulation argument is covered [here](http://www.simulation-argument.com/simulation.html). There are a number of resources -- papers, interviews, an FAQ -- related to the idea [here](http://www.simulation-argument.com/).

# Sources
<a name="citation-1"></a>
1. Given the conditions of factory farms (Wikipedia has [the most neutral article I could find](http://en.wikipedia.org/wiki/Factory_farming)), it is hard to imagine how this could be otherwise. 
<a name="citation-2"></a>
2. Pimentel, David, and Marcia Pimentel. ["Sustainability of meat-based and plant-based diets and the environment."](http://ajcn.nutrition.org/content/78/3/660S.full) The American Journal of Clinical Nutrition 78.3 (2003): 660S-663S.
<a name="citation-3"></a>
3. Singer, Peter. Practical ethics. Cambridge University Press, 1993.
<a name="citation-4"></a>
4. Steinfeld, Henning, et al. [Livestock's long shadow.](ftp://ftp.fao.org/docrep/fao/010/a0701e/a0701e.pdf) Rome: FAO, 2006.
<a name="citation-5"></a>
5. Appleby, Paul N., et al. ["The Oxford vegetarian study: an overview."](http://ajcn.nutrition.org/content/70/3/525s.full.pdf) The American journal of clinical nutrition 70.3 (1999): 525s-531s.
<a name="citation-6"></a>
6. Key, Timothy J., et al. ["Mortality in vegetarians and nonvegetarians: detailed findings from a collaborative analysis of 5 prospective studies."](http://www.direct-ms.org/sites/default/files/Veg%20vs%20non%20veg%20mortality.pdf) The American journal of clinical nutrition 70.3 (1999): 516s-524s.
<a name="citation-7"></a>
7. Bostrom, Nick. ["Existential Risk Prevention as Global Priority."](http://www.existential-risk.org/concept.html) Global Policy 4.1 (2013): 15-31.
<a name="citation-8"></a>
8. Sandberg, Anders, and Nick Bostrom. ["Global catastrophic risks survey."](http://www.fhi.ox.ac.uk/gcr-report.pdf) civil wars 98.30 (2008): 4.
