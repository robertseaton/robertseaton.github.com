---
title: "Deliberate Practice"
layout: post
---

> That which we persist in doing becomes easier, not that the task itself has
> become easier, but that our ability to perform it has improved.
<span id="quote-attribute">—Ralph Waldo Emerson</span>

Malcom Gladwell dragged the notion of deliberate practice into the public
lexicon with the publication of his book *Outliers*. In short, world class
performance depends not on talent, but on thousands of hours of a special sort
of practice, *deliberate practice.*

Now, it's straightforward that practice is the route to improvement of some
skill. Take typing. I can type without effort. I'm not thinking about the keys
or the movement right now, but instead operating at a higher level of sentence
construction. My performance wasn't always this way, though. Typing used to be a
horrible, frustrating affair, and I know this because I'll experience that
frustration again if I switch to an alternate keyboard layout like Dvorak.

# What makes practice deliberate?

There are a few characteristics of deliberate practice:

* **It's effortful.** If it wasn't, everyone would do it and it would no longer
   separate world class performers from everyone else.
* **It's designed to improve performance.** Deliberate practice is about leaving your comfort zone and pushing your limits. It consists of taking something you don't understand how to do, sitting down and
   repeating it until mastery has been achieved. It makes you feel dumb.
* **There's feedback.** You can tell whether or not you're doing it right and
   modify your performance to achieve the "right way" of performing.
   
Daniel Coyle, who wrote *The Talent Code*, put it this way:

1. Pick a target
2. Reach for it
3. Evaluate the gap between the target and the reach
4. Return to step one

# On Plateaus

One might wonder: why do we need a form of practice different than normal
practice?  The answer is that eventually performance platueas. One might drive
their entire life, but never become as skilled as a racecar driver, since their
performance platuead after they learned how to drive and has not improved much
since. The same is true of typing. I learned how to type long ago, but my speed
has long since capped out at about 90 words per minute and not moved since.

Generally, learning a skill seems to at first require our full attention and to
be effortful and, after time, giving way to automaticity, where we no longer
have to think about it. At this point, performance plateaus and further
improvement must be targeted. 

# Breaking Down Skills

To practice deliberately, then, one ought to break a skill down into small
components, each which can be practiced, and then repeat those skills until
automaticity has been achieved, at which point one can work on further
refinement. This is the road to mastery.

As an example, before one can learn to program, one needs to learn a number of
subskills, such as general computer literacy (which can further be broken down),
the syntax of a programming language, familiarity with different control
structures, a text editor, and so on. To write a web application, there is still
more, like familiarity with how the entire stack works. You'll probably want
some knowledge of the command line, too, and so on. Before all this, one ought
to be able to type and so on.

The same is true of any skill. Improving one's understanding of calculus, for
example, at least the mechanical parts, consists of one learning to solve
different forms of integrals and derivatives. Don't forget mundane details like
work organized, either! Once mastery on the simpler ones
has been attained, one can move on to more complex ones, multivariable calculus,
and so on, leading one higher and higher on the infinite ladder that is mathematics.

Indeed, even all of these are at too high a level, each of which should be
broken down further. You need to consider the answer to questions like: what
does expertise in this field look like? How can I quantify it? What are some
goals that would let me know that I'm improving? Keeping a checklist of these
goals is a great idea. 

To do the impossible, break it down into small bits of possible. 

# Paying Attention and Neural Reconfiguration

> A man is what he thinks about all day long.
<span id="quote-attribute">—Ralph Waldo Emerson (again!)</span>

There is an [awesome post over on LessWrong](http://lesswrong.com/lw/blr/attention_control_is_critical_for/) about the relationship between neural
reconfiguration and attention, which ties together nicely with the earlier
discussion of automaticity. The basic idea is that your brain wires
whatever it is that you pay attention to. The more often you lean on a neural
structure, the more it grows.

Consider mindless practicing: sitting down with a guitar, running through a
song haphazard, missing notes like a drunk misses stop signs. In contrast,
consider playing through a song with intense focus on every note and
fingering. The second sounds like it's going to be a whole hell of a lot more
effective and we have the science to back it up: take a group of humans and
compare brain mass based on whether or not they were paying attention during the
task. This has been done.<a href="#citation-1"><sup>1</sup></a> *Attention makes
the brain grow.*

It's as if there is Attention, king of the Neuronal people and, when he becomes
interested in something -- like mathematics -- he yells to his people,
"Optimize my kingdom for mathematics!" and the people build math
libraries and put chalk boards everywhere. 
 
## How can one improve one's attention?

There are a few ways I can think of to improve attention. There are stimulants,
like caffeine, nicotine, modafanil, and adderall. Beyond that, you can go meta
and try to improve attention by paying attention to attention which means --
hooray! -- you've invented Vipassana meditation, the best introduction to which
is either [*Mindfulness in Plain English*](http://www.urbandharma.org/udharma4/mpe.html) or Daniel Ingram's
[*Mastering the Core Teachings of the Buddha*](http://static.squarespace.com/static/5037f52d84ae1e87f694cfda/t/5055915f84aedaeee9181119/1347785055665/),
both of which are free. There's always blocking out distractions (turn off the television!), too, and
setting aside time blocks when you'll worry about only one thing, perhaps via
Pomodoros. 

# Expert Memory, Insight and Recognition

![Garry Kasparov playing chess against children.](/img/kasparov-simultaneous.jpg)

In 2001, Anna-Maria Botsari played 1102 chess matches simulatenously, winning
1095 of the matches and drawing 7. Perhaps even more impressive, Marc Lang holds
the record for simultaneous *blindfold* chess, having played 46 matches at
once, winning 19, drawing 13, and losing 3. (Blindfold chess, for the unaware,
is when one plays without a board and is forced to keep all of the positions in
memory.)

I have enough trouble remembering the 7 digits of a telephone number. More than 1400 board positions? Not a chance.

Or so you might think, but it turns out that any high-ranked chess player can
play blindfold chess. It's not an innate ability, but something acquired over
years of practice. These sort of amazing feats rely on something that's been
dubbed *long-term working memory*.

The basic idea behind long-term working memory is that the superior memory of
experts is the result of years of training, which allows one to access long-term
memory in novel ways. This allows for feats like blind-fold chess. (For a
poignant example of this, check out the book *Moonwalking with Einstein.*)

The earliest evidence for this comes from de Groot's classic study of
chess recall.<a href="#citation-2"><sup>2</sup></a> 
 He took groups stratified by chess ability and showed them
different board positions, which he later asked them to recall. The better a
person was at chess, the better their recall of board positions. The more
interesting result, though, is that de Groot found that this only held when the
board had structured board positions of the sort one would see in actual
play. When he showed subjects randomized board positions, experts did as poorly
as novices. This has been replicated a number of times in chess,<a
href="#citation-3"><sup>3,</sup></a><a href="#citation-4"><sup>4</sup></a> 



This is *chunking*. An untrained individual can hold about seven
(plus or minus two) numbers in short-term memory at one time. Short term memory,
then, is limited, but one can get around this via chunking. Given the right
structure, like a meaningful chess board position, larger *chunks* can be held in
memory. When reading, for instance, one doesn't hold individual letters in
memory, but entire words. The letters have been chunked into words.

Imagine a machine that can only hold four concepts in memory at any one
time. Thinking "Red barking dog eating" would fill all available memory, but it
has a way around this -- a `glue` function which, while
computationally expensive, allows it to glue concepts together to create a new
concept. For example, it could take "barking" and "dog," glue them together, and
create a new concept, "barking dog." Now the machine could hold "Red + barking
dog + eating" in memory and still have room for one more concept.

I propose that this is how expert memory works, with humans having some sort of
equivalent of the `glue` function that takes place during deliberate
practice. Herbert Simon estimates that each chunk takes about 30 seconds of
focused attention to create, with an expert having created somewhere between
50,000 and 1.8 million chunks -- about 10 years of four hours of practice per
day.

## From Whence Intuition Springeth

Experts are often distinguished by their intuition. Consider the blitz style of
play in chess. Specifics vary, but in general it works that each side has five
minutes on the clock and a limit of ten seconds per turn. The conditions make it
so one has to move without thought, relying on intuition.

It should be of no surprise that stronger chess players trounce weaker ones in
blitz matches, but how does it work? From whence does intuition spring? The
answer is long-term memory. It works sort of like this: when the brain creates a
chunk, it's saved in long-term memory. A chess master who has studied many
matches has created tens or hundreds of thousands of such chunks, with each
chunk being something like a board position and what moves are strong and which
aren't. What looks like intuition is the brain pattern-matching against what is
has seen before. The chess player looks at the board, similar positions and
strong moves are automatically retreived from long-term memory, and he makes one
of those moves.

*Insight is the fast, effortless recall of cached experienced.* This is memoization. Instead of computing
 something several times, save it in memory and look it up when you need it. I
 propose that the human brain works in a similar manner: when we meet with a
 novel experience or problem, we're forced to use effortful computation to solve
 it, which is then chunked and saved in long-term memory. In the future, similar
 problems are solved by looking it up.

## Mental Molasses and Slow Minds

> You have to be fast only to catch fleas.
<span id="quote-attribute">—Israel Gelfand, Soviet mathematician</span>

An individual neuron can fire
[anywhere between 1 and 200 times per second.](http://neuroblog.stanford.edu/?p=4541)
This is sorta the equivalent of clock speed of a processor, where each neuron in the
brain is a simple processor. Neurons operate at a top speed of 200 hertz,
though, while a modern processor can hit speeds of nearly 4 gigahertz, or 4
billion hertz. This means that -- and this is a rough comparison -- a CPU is 20
million times faster than one neuron.

The difference, though, is that where a modern CPU might have between four and
eight of these ultra-fast processors (and more in the future!), a brain has
about a hundred billion neurons. It's *the* parallel processor.

But this doesn't do anything about serial problems, where one neuron is going to
be the bottleneck. 200 serial steps -- and you can't do much in 200 steps -- in the brain will take *one second*, and
there are a whole lot of problems that can't be parallelized. (This complexity
class is called [P-complete](http://en.wikipedia.org/wiki/P-complete).) So
what's going on?

Jeff Hawking answers this in his book *On Intelligence*:
> The answer is the brain doesn't "compute" the answers to problems; it
> retrieves the answers from memory.

Sound familiar? The brain is a giant cache. Sure, it computes, too, but it's
slow. Most of our thought is probably retrieval from long-term memory. You can even observe this during
conversation, which is almost never the creation of novel thoughts, but mostly
the repeating of things you've thought and heard before. 
- about changing long term memory


# Sources

<a name="citation-1"></a>
1. Stefan, Katja, Matthias Wycislo, and Joseph Classen. ["Modulation of associative human motor cortical plasticity by attention."](http://jn.physiology.org/content/92/1/66.short) *Journal of Neurophysiology* 92.1 (2004): 66-72.
<a name="citation-2"></a>
2. de Groot, Adriaan David Cornets, and Adrianus Dingeman de Groot. *Thought and
choise in chess.* Vol. 4. Walter de Gruyter, 1978.
<a name="citation-3"></a>
2. Frey, Peter W., and Peter Adesman. "Recall memory for visually presented chess positions." *Memory & Cognition* 4.5 (1976): 541-547.
<a name="citation-4"></a>
4. Chase, William G., and Herbert A. Simon. "Perception in chess." *Cognitive psychology* 4.1 (1973): 55-81.
